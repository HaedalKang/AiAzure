# Computer Vision의 기본 사항

## 목차
- [Computer Vision의 기본 사항](#computer-vision의-기본-사항)
  - [목차](#목차)
  - [소개](#소개)
  - [이미지 및 이미지 처리](#이미지-및-이미지-처리)
    - [픽셀 배열로서의 이미지](#픽셀-배열로서의-이미지)
    - [필터를 사용하여 이미지 처리](#필터를-사용하여-이미지-처리)
  - [Computer Vision을 위한 기계 학습](#computer-vision을-위한-기계-학습)
    - [CNN(나선형 신경망)](#cnn나선형-신경망)
    - [변환기 및 다중 모달 모델](#변환기-및-다중-모달-모델)
      - [변환기](#변환기)
      - [다중 모달 모델](#다중-모달-모델)
  - [Azure AI Vision](#azure-ai-vision)
    - [Azure AI 비전 서비스를 위한 Azure 리소스](#azure-ai-비전-서비스를-위한-azure-리소스)
    - [Azure AI 비전 서비스를 사용하여 이미지 분석](#azure-ai-비전-서비스를-사용하여-이미지-분석)
    - [광학 문자 인식](#광학-문자-인식)
    - [캡션을 사용하여 이미지 설명](#캡션을-사용하여-이미지-설명)
    - [이미지에서 공통 개체 검색](#이미지에서-공통-개체-검색)
    - [시각적 특징 태그 지정](#시각적-특징-태그-지정)
    - [사용자 지정 모델 학습](#사용자-지정-모델-학습)
      - [이미지 분류](#이미지-분류)
      - [개체 감지](#개체-감지)
  - [연습 - Vision Studio에서 이미지 분석](#연습---vision-studio에서-이미지-분석)
  - [요약](#요약)
  - [출처](#출처)

## 소개

‘컴퓨터 비전’은 AI(인공 지능)의 핵심 영역 중 하나이며 AI 애플리케이션이 세상을 “보고” 이해할 수 있는 솔루션을 만드는 데 중점을 둡니다.

컴퓨터는 당연히 인간과 같은 생물학적 눈이 없지만 라이브 카메라 피드나 디지털 사진 또는 비디오로 이미지를 처리할 수 있습니다. 이미지를 처리하는 이 기능은 인간의 시각적 인식을 모방할 수 있는 소프트웨어를 만드는 핵심입니다.

이 모듈에서는 컴퓨터 비전의 기반이 되는 몇몇 기본 원칙과 기술을 살펴봅니다. 더불어 개발자가 다양한 컴퓨터 비전 솔루션을 만드는 데 사용할 수 있는 클라우드 서비스인 Microsoft Azure AI 비전을 소개합니다.

---
## 이미지 및 이미지 처리

이미지 처리 및 기타 컴퓨터 비전 기능을 살펴보기 전에 먼저 컴퓨터 프로그램의 데이터 맥락에서 실질적 이미지의 의미를 고려해 보는 것이 좋습니다.

### 픽셀 배열로서의 이미지

컴퓨터에서 이미지는 픽셀 숫자 값의 배열입니다. 예를 들어 다음 배열을 생각해 보겠습니다.

```
 0   0   0   0   0   0   0  
 0   0   0   0   0   0   0
 0   0  255 255 255  0   0
 0   0  255 255 255  0   0
 0   0  255 255 255  0   0
 0   0   0   0   0   0   0
 0   0   0   0   0   0   0
```

배열은 7x7 픽셀 이미지(이미지의 해상도라고 함)의 픽셀 값을 나타내는 7개 행과 7개 열로 구성됩니다. 각 픽셀의 값은 0(검정)에서 255(흰색) 사이이며, 두 경계 사이의 값은 회색 음영을 나타냅니다. 이 배열로 표시되는 이미지는 다음 이미지(확대 표시)와 유사합니다.

![](../img/white-square.png)

이 이미지의 픽셀 값 배열은 2차원(행과 열을 나타내는 x와 y의 좌표)이며 픽셀 값의 단일 사각형을 정의합니다. 이와 같은 픽셀 값의 단일 레이어는 회색조 이미지를 나타냅니다. 실제로 대부분의 디지털 이미지는 다차원이며 빨강, 녹색, 파랑(RGB) 색상 색조를 나타내는 세 개의 레이어(채널이라고 함)로 구성됩니다. 예를 들어 이전 회색조 예시와 동일한 사각형 도형을 만드는 픽셀 값의 세 채널을 정의하여 색 이미지를 나타낼 수 있습니다.

```
Red:
 150  150  150  150  150  150  150  
 150  150  150  150  150  150  150
 150  150  255  255  255  150  150
 150  150  255  255  255  150  150
 150  150  255  255  255  150  150
 150  150  150  150  150  150  150
 150  150  150  150  150  150  150

Green:
 0    0    0    0    0    0    0          
 0    0    0    0    0    0    0
 0    0   255  255  255   0    0
 0    0   255  255  255   0    0
 0    0   255  255  255   0    0
 0    0    0    0    0    0    0
 0    0    0    0    0    0    0

Blue:
 255  255  255  255  255  255  255  
 255  255  255  255  255  255  255
 255  255   0    0    0   255  255
 255  255   0    0    0   255  255
 255  255   0    0    0   255  255
 255  255  255  255  255  255  255
 255  255  255  255  255  255  255
```

결과 이미지는 다음과 같습니다.

![](../img/color-square.png)

보라색 사각형은 조합으로 표시됩니다.
```
Red: 150 
Green: 0 
Blue: 255
```

가운데의 노란색 사각형은 조합으로 표시됩니다.
```
Red: 255
Green: 255
Blue: 0
```

### 필터를 사용하여 이미지 처리

이미지 처리 작업을 수행하는 일반적인 방법은 이미지의 픽셀 값을 수정하는 필터를 적용하여 시각적 효과를 만드는 것입니다. 필터는 필터 커널이라고 하는 하나 이상의 픽셀 값 배열로 정의됩니다. 가령 다음 예시와 같이 3x3 커널을 사용하여 필터를 정의할 수 있습니다.

```
-1 -1 -1
-1  8 -1
-1 -1 -1
```

그런 다음 커널이 이미지 전체에 연결되고 픽셀의 각 3x3 패치에 대한 가중치 합계를 계산하고 결과를 새 이미지에 할당합니다. 단계별 예를 살펴봄으로써 필터링의 작동 방식을 더 쉽게 이해할 수 있습니다.

앞에서 살펴본 회색조 이미지부터 시작해 보겠습니다.

```
 0   0   0   0   0   0   0  
 0   0   0   0   0   0   0
 0   0  255 255 255  0   0
 0   0  255 255 255  0   0
 0   0  255 255 255  0   0
 0   0   0   0   0   0   0
 0   0   0   0   0   0   0
 ```

먼저 이미지의 왼쪽 위 패치에 필터 커널을 적용하여 각 픽셀 값에 커널의 해당 가중치 값을 곱하고 결과를 더합니다.

```
(0 x -1) + (0 x -1) + (0 x -1) +
(0 x -1) + (0 x 8) + (0 x -1) +
(0 x -1) + (0 x -1) + (255 x -1) = -255
```

결과(-255)가 새 배열의 첫 번째 값이 됩니다. 그런 다음 한 픽셀을 따라 필터 커널을 오른쪽으로 이동하고 작업을 반복합니다.

```
(0 x -1) + (0 x -1) + (0 x -1) +
(0 x -1) + (0 x 8) + (0 x -1) +
(0 x -1) + (255 x -1) + (255 x -1) = -510
```

다시 결과가 새 배열에 추가되어 이제 두 개의 값이 있습니다.

```
-255  -510
```

이 애니메이션에 표시된 것처럼 프로세스는 필터가 이미지 전체에서 컨볼루션될 때까지 반복됩니다.

![](../img/filter.gif)

필터가 이미지 전체에서 컨볼루션되어 새 값의 배열을 계산합니다. 일부 값은 0~255 픽셀 값 범위를 벗어나므로 값이 이 범위에 맞게 조정됩니다. 필터의 모양 때문에 픽셀의 바깥쪽 가장자리는 계산되지 않고 안쪽 여백 값(일반적으로 0)이 적용됩니다. 결과 배열은 필터가 원래 이미지를 변환한 결과물인 새 이미지를 나타냅니다. 이 경우에서는 필터가 이미지 모양의 가장자리를 강조 표시하는 효과가 있습니다.

다음은 필터의 효과를 더욱 명확하게 확인할 수 있는 실제 이미지에 적용된 동일한 필터의 예시입니다.

|원본 이미지|필터링된 이미지|
|---|---|
|![](../img/banana-grayscale.png)|![](../img/laplace.png)|

필터가 이미지 전체에서 컨볼루션되기 때문에 이러한 종류의 이미지 조작을 나선형 필터링이라고도 합니다. 이 예에 사용된 필터는 이미지의 개체에 대한 가장자리를 강조 표시하는 특정 유형의 필터(라플라스 필터라고 함)입니다. 흐리게, 선명하게, 색 반전 및 기타 효과를 만드는 데 사용할 수 있는 다른 많은 종류의 필터가 있습니다.

---
## Computer Vision을 위한 기계 학습

필터를 사용하여 이미지에 효과를 적용하는 기능은 이미지 편집 소프트웨어를 사용하여 작업하는 것과 같이 이미지 처리 작업에 유용합니다. 하지만 컴퓨터 비전의 목표는 이미지에서 의미, 또는 적어도 실행 가능한 통찰력을 추출하는 것이기도 하며, 이를 위해서는 대량의 기존 이미지를 기반으로 특징을 인식하도록 학습하는 기계 학습 모델을 만들어야 합니다.

팁
```
이 단원에서는 여러분이 기계 학습의 기본 원칙에 익숙하고 신경망을 사용한 딥 러닝에 대한 개념적 지식을 갖추고 있다고 가정합니다. 기계 학습을 처음 접하는 경우라면 Microsoft Learn의 기계 학습의 기본 사항 모듈을 먼저 완료하는 것이 좋습니다.
```

### CNN(나선형 신경망)

컴퓨터 비전의 가장 일반적인 기계 학습 모델 아키텍처 가운데 하나는 CNN(나선형 신경망)입니다. CNN은 필터를 사용하여 이미지에서 숫자 특징 맵을 추출한 다음, 특징 값을 딥 러닝 모델에 공급하여 레이블 예측을 생성합니다. 예를 들어 이미지 분류 시나리오에서 레이블은 이미지의 주요 주제 즉, 이 이미지가 무엇인지를 나타냅니다. 예측되는 레이블이 한 이미지에서 과일 유형이 되도록 다양한 과일 종류(예: 사과, 바나나, 오렌지)의 이미지를 사용하여 CNN 모델을 학습할 수 있습니다.

CNN 학습 프로세스 중에 필터 커널은 처음에 임의로 생성된 가중치 값을 사용하여 정의됩니다. 그런 다음, 학습 프로세스가 진행됨에 따라 모델 예측이 알려진 레이블 값에 대해 평가되고 필터 가중치가 조정되어 정확도가 향상됩니다. 결국 학습된 과일 이미지 분류 모델은 다양한 종류의 과일을 식별하는 데 도움이 되는 특징을 가장 잘 추출하는 필터 가중치를 사용합니다.

다음 다이어그램은 이미지 분류 모델의 CNN이 작동하는 방식을 보여줍니다.

![](../img/convolutional-neural-network.png)

 - 알려진 레이블(예: 사과 0, 바나나 1, 오렌지 2)이 있는 이미지가 네트워크에 공급되어 모델을 학습합니다.
 - 네트워크를 통해 공급되는 각 이미지에서 특징을 추출하는 데 하나 이상의 필터 레이어가 사용됩니다. 필터 커널은 임의로 할당된 가중치로 시작하고 특징 맵이라는 숫자 값 배열을 생성합니다.
 - 특징 맵은 특징 값의 1차원 배열로 평면화됩니다.
 - 특징 값은 완전히 연결된 신경망에 공급됩니다.
 - 신경망의 출력 레이어는 softmax 또는 유사한 함수를 사용하여 각 가능한 클래스의 확률 값(예: [0.2, 0.5, 0.3])이 포함된 결과를 생성합니다.

학습 동안 출력 확률은 실제 클래스 레이블과 비교됩니다. 예를 들어 바나나(클래스 1)의 이미지는 [0.0, 1.0, 0.0] 값을 가질 것입니다. 예측 클래스 점수와 실제 클래스의 점수 차이는 모델에서 손실을 계산하는 데 사용되며, 완전히 연결된 신경망의 가중치와 특징 추출 레이어의 필터 커널은 손실을 줄이기 위해 수정됩니다.

학습 프로세스는 최적의 가중치 집합이 학습될 때까지 여러 epoch에 걸쳐 반복됩니다. 그런 다음 가중치를 저장하고 모델을 사용하여 레이블을 알 수 없는 새 이미지의 레이블을 예측할 수 있습니다.

참고
```
CNN 아키텍처는 일반적으로 특징 맵의 크기를 줄이고 추출된 값을 제한하고 특징 값을 조작할 수 있도록 여러 나선형 필터 레이어와 추가 레이어가 포함되어 있습니다. 이 간소화된 예에서는 필터를 사용하여 이미지에서 숫자 특징을 추출한 다음, 신경망에서 이미지 레이블을 예측하는 데 사용되는 주요 개념에 집중하기 위해 이러한 레이어를 생략했습니다.
```

### 변환기 및 다중 모달 모델

CNN은 수년 동안 컴퓨터 비전 솔루션의 핵심이었습니다. 앞서 설명한 대로 CNN은 흔히 이미지 분류 문제를 해결하는 데 사용되지만 더 복잡한 컴퓨터 비전 모델의 기초가 되기도 합니다. 예를 들어 개체 감지 모델은 CNN 특징 추출 레이어를 이미지의 관심 영역 식별과 결합하여 같은 이미지에서 개체에 대한 여러 클래스를 찾습니다.

#### 변환기

수십 년 동안 컴퓨터 비전 발전의 대부분은 CNN 기반 모델을 개선함으로써 추진되었습니다. 하지만 또 다른 AI 분야인 NLP(자연어 처리)에서 변환기라 불리는 또 다른 유형의 신경망 아키텍처는 정교한 언어 모델을 개발할 수 있도록 했습니다. 변환기는 대량의 데이터를 처리하고 개별 단어 또는 구를 나타내는 언어 토큰을 벡터 기반 임베딩 (숫자 값 배열)으로 인코딩하여 작동합니다. 임베딩은 각각 토큰의 어떤 의미 체계 특성을 나타내는 차원들의 집합을 대표하는 것으로 생각할 수 있습니다. 임베딩은 동일한 컨텍스트에서 흔히 사용되는 토큰들이 관련 없는 단어들보다 차원적으로 서로 더 가까워지도록 만들어집니다.

간단한 예로 다음 다이어그램은 3차원 벡터로 인코딩되고 3차원 공간에 그려진 몇 개의 단어를 보여줍니다.

![](../img/language-encoder.png)

의미상 유사한 토큰들이 비슷한 위치에 인코딩되어 텍스트 분석, 번역, 언어 생성 및 기타 작업을 위한 정교한 NLP 솔루션을 빌드할 수 있는 의미 체계 언어 모델을 만듭니다.

참고
```
여기서는 시각화하기 쉬운 3차원만 사용했습니다. 실제로 변환기 네트워크의 인코더는 더 많은 차원의 벡터를 만들어 선형 대수 계산을 기반으로 토큰 간의 복잡한 의미 체계 관계를 정의합니다. 관련된 수학은 변환기 모델의 아키텍처와 마찬가지로 복잡합니다. 여기서의 목표는 인코딩이 엔터티 간의 관계를 캡슐화하는 모델을 만드는 방법에 대한 개념적 이해를 돕는 것입니다.
```

#### 다중 모달 모델

변환기가 언어 모델을 빌드하는 방법으로 성공하자 AI 연구원들은 동일한 접근 방식이 이미지 데이터에도 효과적일 수 있을지를 고려하게 되었습니다. 그 결과 고정된 레이블이 없는 대량의 캡션 이미지를 사용하여 모델을 학습하는 다중 모달 모델이 개발되었습니다. 이미지 인코더는 픽셀 값을 기반으로 이미지에서 특징을 추출한 다음, 언어 인코더에서 만든 텍스트 인베딩과 결합합니다. 전체 모델은 다음과 같이 자연어 토큰 임베딩과 이미지 특징 간의 관계를 캡슐화합니다.

![](../img/multi-modal-model.png)

Microsoft의 Florence 모델이 바로 그러한 모델입니다. 인터넷에서 대량의 캡션 이미지로 학습된 이 모델에는 언어 인코더와 이미지 인코더가 모두 포함되어 있습니다. Florence는 기초 모델의 한 예입니다. 즉, 전문가 작업에서 여러 적응형 모델을 빌드할 수 있도록 미리 학습된 범용 모델입니다. 예를 들어 다음을 수행하는 적응형 모델의 기초 모델로 Florence를 사용할 수 있습니다.

 - 이미지 분류: 이미지가 속한 범주를 식별합니다.
 - 개체 감지: 이미지에서 개별 개체를 찾습니다.
 - 캡션: 이미지에 대한 적절한 설명을 생성합니다.
 - 태그 지정: 이미지에 대한 관련 텍스트 태그 목록을 컴파일합니다.

![](../img/florence-model.png)

Florence와 같은 다중 모달 모델은 전반적으로 컴퓨터 비전과 AI의 최첨단에 있으며 AI가 만드는 솔루션 종류의 발전을 이끌어갈 것으로 예상됩니다.

---
## Azure AI Vision

Computer Vision을 위한 자체 기계 학습 모델을 학습할 수 있지만 Computer Vision 모델의 아키텍처는 복잡할 수 있습니다. 그리고 학습 프로세스를 수행하려면 상당한 양의 학습 이미지와 컴퓨팅 능력이 필요합니다.

Microsoft의 Azure AI 비전 서비스는 Florence 기반 모델을 기반으로 하며 다양하고 강력한 기능을 제공하는 미리 빌드되고 사용자 지정 가능한 Computer Vision 모델을 제공합니다. Azure AI 비전을 사용하면 정교한 Computer Vision 솔루션을 빠르고 쉽게 만들 수 있습니다. 많은 일반적인 Computer Vision 시나리오에 대해 "상용 제품" 기능을 활용하는 동시에 고유의 이미지를 사용하여 사용자 지정 모델을 만들 수 있는 기능을 보존합니다.

### Azure AI 비전 서비스를 위한 Azure 리소스

Azure AI 비전을 사용하려면 Azure 구독에서 이에 대한 리소스를 만들어야 합니다. 다음 리소스 유형 중 하나를 사용할 수 있습니다.

 - Azure AI 비전: Azure AI 비전 서비스에 대한 특정 리소스입니다. 다른 Azure AI 서비스를 사용하지 않으려는 경우이거나 Azure AI 비전 리소스의 사용률과 비용을 별도로 추적하려는 경우 이 리소스 종류를 사용합니다.
 - Azure AI 서비스: 다른 많은 Azure AI 서비스와 함께 Azure AI 비전을 포함하는 일반 리소스입니다. Azure AI 언어, Azure AI Custom Vision, Azure AI 번역기 등이 있습니다. 여러 AI 서비스를 사용할 계획이고 관리 및 개발을 단순화하려는 경우 이 리소스 유형을 사용하세요.

### Azure AI 비전 서비스를 사용하여 이미지 분석

구독에서 적합한 리소스를 만든 후에는 Azure AI 비전 서비스에 이미지를 제출하여 광범위한 분석 작업을 수행할 수 있습니다.

Azure AI 비전은 다음을 포함한 여러 이미지 분석 기능을 지원합니다.

 - OCR(광학 인식) - 이미지에서 텍스트를 추출합니다.
 - 이미지의 캡션 및 설명을 생성합니다.
 - 이미지에서 수천 개의 공통 개체를 검색합니다.
 - 이미지의 시각적 기능에 태그 지정

이러한 작업 등은 Azure AI 비전 스튜디오에서 수행할 수 있습니다.

![](../img/vision-studio.png)

### 광학 문자 인식

Azure AI 비전 서비스는 OCR(광학 인식) 기능을 사용하여 이미지의 텍스트를 검색할 수 있습니다. 예를 들어, 식료품점에 있는 제품의 영양 레이블 이미지를 생각해 보세요.

![](../img/nutrition-label.png)

Azure AI 비전 서비스는 이 이미지를 분석하고 다음 텍스트를 추출할 수 있습니다.

```
Nutrition Facts Amount Per Serving
Serving size:1 bar (40g)
Serving Per Package: 4
Total Fat 13g
Saturated Fat 1.5g
Amount Per Serving
Trans Fat 0g
calories 190
Cholesterol 0mg
ories from Fat 110
Sodium 20mg
ntDaily Values are based on
Vitamin A 50
calorie diet
```

```
Microsoft Learn의 Azure AI 비전으로 텍스트 읽기 모듈에서 Azure AI 비전의 OCR 기능을 자세히 살펴볼 수 있습니다.
```

### 캡션을 사용하여 이미지 설명

Azure AI 비전에는 이미지를 분석하고, 검색된 개체를 평가하고, 이미지에서 감지된 내용을 설명할 수 있는 사람이 읽을 수 있는 문구나 문장을 생성하는 기능이 있습니다. 예를 들어 다음과 같은 이미지를 생각해 보세요.

![](../img/skateboard.png)

Azure AI 비전은 이 이미지에 대해 다음 캡션을 반환합니다.

```
스케이트보드를 타고 점프하는 남자
```

### 이미지에서 공통 개체 검색

Azure AI 비전은 이미지에서 수천 개의 공통 개체를 식별할 수 있습니다. 예를 들어, 이전에 설명한 스케이트보더 이미지에서 개체를 검색하는 데 사용되는 경우 Azure AI 비전은 다음 예측을 반환합니다.

 - 스케이트보드(90.40%)
 - 사람(95.5%)

예측에는 모델이 예측된 개체에 대해 계산한 확률을 나타내는 신뢰도 점수가 포함됩니다.

검색된 개체 레이블 및 해당 확률 외에도 Azure AI 비전은 검색된 개체의 위쪽, 왼쪽, 너비 및 높이를 나타내는 경계 상자 좌표를 반환합니다. 다음과 같이 이러한 좌표를 사용하여 이미지에서 각 개체가 검색된 위치를 확인할 수 있습니다.

![](../img/bounding-boxes.png)

### 시각적 특징 태그 지정

Azure AI 비전은 콘텐츠를 기반으로 이미지에 대한 태그를 제안할 수 있습니다. 이러한 태그는 이미지의 특성을 요약하는 메타데이터로 이미지와 연결될 수 있으며, 특정 특성이나 콘텐츠가 있는 이미지를 검색하는 데 사용할 수 있는 주요 용어 집합과 함께 이미지를 인덱스화하려는 경우 유용할 수 있습니다.

예를 들어, 스케이트보더 이미지에 대해 반환된 태그(관련 신뢰도 점수 포함)에는 다음이 포함됩니다.

```
스포츠(99.60%)
사람(99.56%)
신발(98.05%)
스케이팅(96.27%)
보드스포츠(95.58%)
스케이트보드 장비(94.43%)
의류(94.02%)
벽(93.81%)
스케이트보드(93.78%)
스케이트보더(93.25%)
개인 스포츠(92.80%)
거리 묘기(90.81%)
잔액(90.81%)
점프(89.87%)
스포츠 장비(88.61%)
익스트림 스포츠(88.35%)
킥플립(88.18%)
스턴트(87.27%)
스케이트보드(86.87%)
스턴트 연기자(85.83%)
무릎(85.30%)
스포츠(85.24%)
롱보드(84.61%)
롱보드(84.45%)
승차(73.37%)
스케이트(67.27%)
공기(64.83%)
젊은층(63.29%)
실외(61.39%)
```

### 사용자 지정 모델 학습

Azure AI 비전에서 제공하는 기본 제공 모델이 요구 사항을 충족하지 않는 경우 서비스를 사용하여 이미지 분류 또는 개체 감지를 위한 사용자 지정 모델을 학습할 수 있습니다. Azure AI 비전은 미리 학습된 기초 모델을 기반으로 사용자 지정 모델을 빌드합니다. 즉, 상대적으로 적은 수의 학습 이미지를 사용하여 정교한 모델을 학습할 수 있습니다.

#### 이미지 분류

이미지 분류 모델은 이미지의 범주 또는 클래스를 예측하는 데 사용됩니다. 예를 들어, 다음과 같이 이미지에 어떤 형식의 과일이 표시되는지 결정하도록 모델을 학습할 수 있습니다.

|사과|바나나|오렌지|
|---|---|---|
|![](../img/apple.png)|![](../img/banana.png)|![](../img/orange.png)|

#### 개체 감지

개체 감지 모델은 이미지의 개체를 검색하고 분류하여 경계 상자 좌표를 반환하여 각 개체를 찾습니다. Azure AI 비전의 기본 제공 개체 감지 기능 외에도 고유한 이미지를 사용하여 사용자 지정 개체 감지 모델을 학습할 수 있습니다. 예를 들어, 다음과 같이 과일 사진을 사용하여 이미지에서 여러 과일을 검색하는 모델을 학습할 수 있습니다.

![](../img/object-detection%20(1).png)

참고
```
Azure AI 비전을 사용하여 사용자 지정 모델을 학습하는 방법에 대한 자세한 내용은 이 모듈의 범위를 벗어납니다. [Azure AI 비전 설명서](https://learn.microsoft.com/ko-kr/azure/ai-services/computer-vision/how-to/model-customization?tabs=python)에서 사용자 지정 모델 학습에 대한 정보를 찾을 수 있습니다.
```
---
## 연습 - Vision Studio에서 이미지 분석

Azure를 구독하고 있는 경우 Vision Studio를 사용하여 Azure AI 비전의 기능을 탐색할 수 있습니다.

TODO : 실습자료 만들기

---
## 요약

컴퓨터 비전은 이미지의 숫자 픽셀 값에 대한 분석과 조작을 기반으로 합니다. 기계 학습 모델은 대량의 이미지를 사용하여 이미지 분류, 개체 감지, 자동화된 이미지 태그 지정, 광학 인식 등과 같은 일반적인 컴퓨터 비전 시나리오를 사용하도록 학습됩니다.

컴퓨터 비전에 대한 사용자 고유의 기계 학습 모델을 만드는 것이 가능하며, Azure AI Vision 서비스를 사용하면 설명 캡션 생성, 관련 태그 추출, 개체 식별 등 이미지를 분석하는 데 사용할 수 있는 다양한 미리 학습된 기능을 활용할 수 있습니다.

```
Azure AI 비전 서비스 사용에 대한 자세한 내용은 [서비스 문서](https://learn.microsoft.com/ko-kr/azure/ai-services/computer-vision/overview)에서 확인할 수 있습니다.
```
---
## 출처
[Microsoft learn Computer Vision의 기본 사항](https://learn.microsoft.com/ko-kr/training/modules/analyze-images-computer-vision/)