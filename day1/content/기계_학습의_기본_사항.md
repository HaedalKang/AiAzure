# 기계 학습의 기본 사항

## 목차
- [기계 학습의 기본 사항](#기계-학습의-기본-사항)
  - [목차](#목차)
  - [소개](#소개)
  - [기계 학습이란 무엇인가요?](#기계-학습이란-무엇인가요)
    - [함수로서의 기계 학습](#함수로서의-기계-학습)
  - [기계 학습 유형](#기계-학습-유형)
    - [감독된 기계 학습](#감독된-기계-학습)
      - [회귀](#회귀)
      - [분류](#분류)
        - [이진 분류](#이진-분류)
          - [다중 클래스 분류](#다중-클래스-분류)
    - [감독되지 않는 기계 학습](#감독되지-않는-기계-학습)
      - [Clustering](#clustering)
  - [회귀](#회귀-1)
    - [예제 - 회귀](#예제---회귀)
      - [회귀 모델 학습](#회귀-모델-학습)
      - [회귀 모델 평가](#회귀-모델-평가)
      - [회귀 평가 메트릭](#회귀-평가-메트릭)
        - [MAE(평균 절대 오차)](#mae평균-절대-오차)
        - [MSE(평균 제곱 오차)](#mse평균-제곱-오차)
        - [RMSE(제곱 평균 오차)](#rmse제곱-평균-오차)
        - [결정 계수($R^2$)](#결정-계수r2)
    - [반복 학습](#반복-학습)
  - [이진 분류](#이진-분류-1)
    - [예제 - 이진 분류](#예제---이진-분류)
      - [이진 분류 모델 학습](#이진-분류-모델-학습)
      - [이진 분류 모델 평가](#이진-분류-모델-평가)
      - [이진 분류 평가 메트릭](#이진-분류-평가-메트릭)
        - [정확도](#정확도)
        - [재현율](#재현율)
        - [정밀도](#정밀도)
        - [F1 점수](#f1-점수)
        - [곡선 아래 면적(AUC)](#곡선-아래-면적auc)
  - [다중 클래스 분류](#다중-클래스-분류-1)
    - [예제 - 다중 클래스 분류](#예제---다중-클래스-분류)
      - [다중 클래스 분류 모델 학습](#다중-클래스-분류-모델-학습)
        - [OvR(One-vs-Rest) 알고리즘](#ovrone-vs-rest-알고리즘)
        - [다항식 알고리즘](#다항식-알고리즘)
      - [다중 클래스 분류 모델 평가](#다중-클래스-분류-모델-평가)
  - [Clustering](#clustering-1)
    - [예제 - 클러스터링](#예제---클러스터링)
      - [클러스터링 모델 학습](#클러스터링-모델-학습)
      - [클러스터링 모델 평가](#클러스터링-모델-평가)
  - [딥 러닝](#딥-러닝)
    - [예제 - 분류에 딥 러닝 사용](#예제---분류에-딥-러닝-사용)
      - [신경망은 어떻게 학습하나요?](#신경망은-어떻게-학습하나요)
  - [Azure Machine Learning](#azure-machine-learning)
    - [Azure Machine Learning의 특징 및 기능](#azure-machine-learning의-특징-및-기능)
    - [Azure Machine Learning 리소스 프로비전](#azure-machine-learning-리소스-프로비전)
    - [Azure Machine Learning Studio](#azure-machine-learning-studio)
  - [연습 - Azure Machine Learning에서 자동화된 Machine Learning 살펴보기](#연습---azure-machine-learning에서-자동화된-machine-learning-살펴보기)
  - [요약](#요약)
  - [출처](#출처)
---
## 소개
기계 학습은 여러 면에서 데이터 과학 및 소프트웨어 엔지니어링이라는 두 분야의 교차점입니다. 기계 학습의 목표는 데이터를 사용하여 소프트웨어 애플리케이션 또는 서비스에 통합할 수 있는 예측 모델을 만드는 것입니다. 이 목표를 달성하려면 데이터를 사용하여 기계 학습 모델을 학습시키기 전에 데이터를 탐색하고 준비하는 데이터 과학자와 새로운 데이터 값을 예측하는 데 사용되는 애플리케이션에 모델을 통합하는 소프트웨어 개발자 간의 협력이 필요합니다(추론이라고 알려진 프로세스).

이 모듈에서는 기계 학습의 기반이 되는 핵심 개념 중 일부를 살펴보고, 다양한 종류의 기계 학습 모델을 식별하는 방법을 알아보고, 기계 학습 모델을 학습하고 평가하는 방법을 살펴봅니다. 마지막으로, 코드를 작성할 필요 없이 Microsoft Azure Machine Learning을 사용하여 기계 학습 모델을 학습하고 배포하는 방법을 알아봅니다.

*참고*
```
기계 학습은 수학 및 통계 기술을 기반으로 하며, 그 중 일부는 이 모듈의 높은 수준에서 설명됩니다. 하지만 수학 전문가가 아니라면 걱정하지 마세요! 이 모듈의 목표는 기계 학습이 어떻게 작동하는지에 대한 직관을 얻도록 돕는 것입니다. 핵심 개념을 이해하는 데 필요한 최소한의 수학을 유지하겠습니다.
```

---
## 기계 학습이란 무엇인가요?

기계 학습은 데이터의 통계 및 수학 모델링에 그 기원을 두고 있습니다. 기계 학습의 기본 개념은 과거 관찰의 데이터를 사용하여 알 수 없는 결과 또는 값을 예측하는 것입니다. 

예시:

 - 아이스크림 가게의 주인은 일기 예보에 따라 특정 날에 판매 할 가능성이 얼마나 많은 아이스크림을 예측하기 위해 과거 판매 기록과 날씨 기록을 결합하는 애플리케이션을 사용할 수 있습니다.
 - 의사는 과거 환자의 임상 데이터를 사용하여 새로운 환자가 체중, 혈당 수준, 기타 측정과 같은 요인에 따라 당뇨병의 위험에 처해 있는지 여부를 예측하는 자동화 된 테스트를 실행할 수 있습니다.
 - 남극의 한 연구원은 과거 관측을 사용하여 새의 물갈퀴, 부리, 기타 신체적 특성의 측정값에 따라 다른 펭귄 종(예: 아델리, 젠투 또는 친스트랩)의 식별을 자동화할 수 있습니다.

### 함수로서의 기계 학습

기계 학습은 수학 및 통계를 기반으로 하기 때문에 기계 학습 모델에 대해 수학 측면에서 생각하는 것이 일반적입니다. 기본적으로 기계 학습 모델은 하나 이상의 입력 값을 기반으로 출력 값을 계산하는 함수를 캡슐화하는 소프트웨어 애플리케이션입니다. 해당 함수를 정의하는 프로세스를 학습이라고 합니다. 함수가 정의되면 이를 사용하여 추론이라는 프로세스에서 새 값을 예측할 수 있습니다.

학습 및 추론과 관련된 단계를 살펴보겠습니다.

![](../img/machine-learning.png)

 1. 학습 데이터는 과거 관찰로 구성됩니다. 대부분의 경우 관찰되는 항목의 관찰된 특성 또는 기능과 예측하도록 모델을 학습하려는 항목의 알려진 값(레이블이라고 함)이 포함됩니다. <br><br>수학 용어로는 약식 변수 이름 $x$를 사용하여 참조하는 기능과 $y$라고 하는 레이블이 표시되는 경우가 많습니다. 일반적으로 관찰은 여러 기능 값으로 구성되므로 $x$는 실제로 다음과 같이 벡터입니다(여러 값이 있는 배열): $[x1,x2,x3,...]$.<br><br>이를 명확하게 하기 위해 앞에서 설명한 예제를 살펴보겠습니다.

    - 아이스크림 판매 시나리오에서 우리의 목표는 날씨에 따라 아이스크림 판매량을 예측할 수 있는 모델을 학습시키는 것입니다. 해당 날짜의 날씨 측정(온도, 강우, 풍속 등)은 기능($x$)이고, 매일 판매되는 아이스크림의 수는 레이블($y$)입니다.
    - 의료 시나리오에서 목표는 임상 측정에 따라 환자가 당뇨병의 위험에 처해 있는지 여부를 예측하는 것입니다. 환자의 측정값(체중, 혈당 수치 등)은 특징($x$)이며 당뇨병 발병 가능성(예 : 위험에 대한 1, 위험하지 않은 경우 0)은 레이블($y$)입니다.
    - 남극 연구 시나리오에서는 신체적 특성에 따라 펭귄의 종을 예측하려고 합니다. 펭귄의 주요 측정값(물갈퀴의 길이, 부리의 너비 등)은 특징($x$)이며 종(예: 아델리의 경우 0, 젠투의 경우 1, 친스트랩의 경우 2)은 레이블($y$)입니다.
 
 2. 데이터에 알고리즘을 적용하여 기능과 레이블 간의 관계를 확인하고 $x$에서 $y$를 계산하기 위해 수행할 수 있는 계산으로 해당 관계를 일반화합니다. 사용되는 특정 알고리즘은 해결하려는 예측 문제의 종류에 따라 달라지지만(나중에 자세히 설명) 기본 원칙은 기능 값을 사용하여 레이블을 계산할 수 있는 데이터에 함수를 맞추는 것입니다.

 3. 알고리즘의 결과는 알고리즘에서 파생된 계산을 함수로 캡슐화하는 모델입니다. 이를 f라고 하겠습니다. 수학 표기법: $y = f(x)$

 4. 이제 학습 단계가 완료되었으므로 학습된 모델을 추론에 사용할 수 있습니다. 모델은 기본적으로 학습 프로세스에서 생성된 함수를 캡슐화하는 소프트웨어 프로그램입니다. 기능 값 집합을 입력하고 해당 레이블의 예측을 출력으로 받을 수 있습니다. 모델의 출력은 관찰된 값이 아니라 함수에 의해 계산된 예측이므로 함수의 출력이 $\hat{y}$로 표시됩니다(“y-hat”라고 귀엽게 표현됩니다).
---
## 기계 학습 유형

기계 학습에는 여러 유형이 있으며 예측하려는 내용에 따라 적절한 형식을 적용해야 합니다. 다음 다이어그램에는 일반적인 유형의 기계 학습에 대한 분석이 나와 있습니다.

![](../img/machine-learning-types.png)

### 감독된 기계 학습
감독 기계 학습은 학습 데이터에 기능 값과 알려진 레이블 값이 모두 포함된 기계 학습 알고리즘의 일반적인 용어입니다. 감독된 기계 학습은 과거 관찰에서 기능과 레이블 간의 관계를 결정하여 모델을 학습시키는 데 사용되므로 향후의 경우 기능에 대해 알 수 없는 레이블을 예측할 수 있습니다.

#### 회귀
회귀는 모델에서 예측한 레이블이 숫자 값인 감독 기계 학습의 한 형태입니다. 예시:

 - 온도, 강우량 및 풍속에 따라 지정된 날에 판매되는 아이스크림의 수.
 - 평방 피트의 크기에 따라 속성의 판매 가격, 포함 된 침실의 수, 그 위치에 대한 사회 경제적 메트릭.
 - 엔진 크기, 무게, 너비, 높이 및 길이에 따라 자동차의 연료 효율(갤런당 마일 단위).

#### 분류
분류는 레이블이 분류 또는 클래스를 나타내는 감독된 기계 학습의 한 형태입니다. 두 가지 일반적인 분류 시나리오가 있습니다.

##### 이진 분류
이진 분류에서 레이블은 관찰된 항목이 특정 클래스의 인스턴스인지(또는 아닌지) 여부를 결정합니다. 또는 이진 분류 모델은 상호 배타적인 두 가지 결과 중 하나를 예측합니다. 예시:

 - 환자가 체중, 나이, 혈당 수준 등과 같은 임상 메트릭에 따라 당뇨병의 위험이 있는지 여부.
 - 은행 고객이 소득, 신용 기록, 연령 및 기타 요인에 따라 대출을 기본값으로 설정할지 여부.
 - 우편물 목록 고객이 인구 통계 특성 및 과거 구매에 따라 마케팅 제안에 긍정적으로 응답할지 여부.

이러한 모든 예제에서 모델은 가능한 단일 클래스에 대해 이진 true/false(참/거짓) 또는 양성/음성 예측을 예측합니다.

###### 다중 클래스 분류

다중 클래스 분류는 이진 분류를 확장하여 가능한 여러 클래스 중 하나를 나타내는 레이블을 예측합니다. 예를 들면 다음과 같습니다.

 - 펭귄의 종(Adelie, Gentoo 또는 Chinstrap)은 물리적 측정을 기반으로 합니다.
 - 영화의 장르(코미디, 공포, 로맨스, 모험, 또는 공상 과학)는 출연진, 감독 및 예산을 기준으로합니다.

여러 클래스의 알려진 집합을 포함하는 대부분의 시나리오에서 다중 클래스 분류는 상호 배타적인 레이블을 예측하는 데 사용됩니다. 예를 들어, 펭귄은 Gentoo이면서 Adelie일 수는 없습니다. 그러나 다중 레이블 분류 모델을 학습하는 데 사용할 수 있는 몇 가지 알고리즘도 있으며, 이 경우 단일 관측치에 대해 둘 이상의 유효한 레이블이 있을 수 있습니다. 예를 들어, 영화는 잠재적으로 공상 과학과 코미디로 분류될 수 있습니다.

### 감독되지 않는 기계 학습

비감독 기계 학습에는 알려진 레이블 없이 기능 값으로만 구성된 데이터를 사용하여 모델을 학습하는 작업이 포함됩니다. 감독되지 않은 기계 학습 알고리즘은 학습 데이터에서 관찰 기능 간의 관계를 결정합니다.

#### Clustering

비감독 기계 학습의 가장 일반적인 형태는 클러스터링입니다. 클러스터링 알고리즘은 해당 기능에 따라 관찰 간의 유사성을 식별하고 개별 클러스터로 그룹화합니다. 예시:

 - 크기, 잎 수 및 꽃잎 수에 따라 비슷한 꽃을 그룹화합니다.
 - 인구 통계 특성 및 구매 동작에 따라 유사한 고객 그룹을 식별합니다.

어떤 면에서 클러스터링 다중 클래스 분류와 유사합니다. 즉, 관찰을 개별 그룹으로 분류합니다. 차이점은 분류를 사용할 때 학습 데이터의 관찰이 속한 클래스를 이미 알고 있다는 것입니다. 알고리즘은 기능과 알려진 분류 레이블 간의 관계를 결정하여 작동합니다. 클러스터링 이전에 알려진 클러스터 레이블이 없으며 알고리즘은 기능의 유사성에 따라 데이터 관찰을 그룹화합니다.

경우에 따라 클러스터링 분류 모델을 학습하기 전에 존재하는 클래스 집합을 결정하는 데 사용됩니다. 예를 들어 클러스터링을 사용하여 고객을 그룹으로 분할한 다음 해당 그룹을 분석하여 다양한 고객 클래스(높은 가치 - 낮은 볼륨, 빈번한 소규모 구매자 등)를 식별하고 분류할 수 있습니다. 그런 다음 분류를 사용하여 클러스터링 결과의 관찰에 레이블을 지정하고 레이블이 지정된 데이터를 사용하여 새 고객이 속할 수 있는 고객 범주를 예측하는 분류 모델을 학습시킬 수 있습니다.

---
## 회귀
회귀 모델은 기능과 알려진 레이블을 모두 포함하는 학습 데이터를 기반으로 숫자 레이블 값을 예측하도록 학습됩니다. 회귀 모델(또는 실제로 감독되는 기계 학습 모델)을 학습하는 프로세스에는 적절한 알고리즘(일반적으로 일부 매개 변수가 있는 설정 포함)을 사용하여 모델을 학습시키고, 모델의 예측 성능을 평가하고, 예측 정확도의 허용 가능한 수준을 달성할 때까지 다양한 알고리즘 및 매개 변수로 학습 프로세스를 반복하여 모델을 구체화하는 여러 반복이 포함됩니다.

![](../img/supervised-training.png)

이 다이어그램은 감독되는 기계 학습 모델에 대한 학습 프로세스의 네 가지 주요 요소를 보여 줍니다.

 1. 학습 데이터를 임의로 분할하여 학습된 모델의 유효성을 검사하는 데 사용할 데이터의 하위 집합을 유지하면서 모델을 학습시킬 데이터 세트를 만듭니다.
 2. 알고리즘을 사용하여 학습 데이터를 모델에 맞춥니다. 회귀 모델의 경우 선형 회귀와 같은 회귀 알고리즘을 사용합니다.
 3. 보류한 유효성 검사 데이터를 사용하여 기능에 대한 레이블을 예측하여 모델을 테스트합니다.
 4. 검증 데이터 세트의 알려진 실제 레이블을 모델이 예측한 레이블과 비교합니다. 그런 다음, 예측된 레이블 값과 실제 레이블 값 간의 차이를 집계하여 모델이 유효성 검사 데이터에 대해 얼마나 정확하게 예측했는지를 나타내는 메트릭을 계산합니다.

각 학습, 유효성 검사 및 평가 반복 후에는 허용되는 평가 메트릭이 달성될 때까지 다양한 알고리즘 및 매개 변수를 사용하여 프로세스를 반복할 수 있습니다.

### 예제 - 회귀

단일 기능 값(x)을 기반으로 숫자 레이블(y)을 예측하도록 모델을 학습시키는 단순화된 예를 통해 회귀를 살펴보겠습니다. 대부분의 실제 시나리오에는 몇 가지 복잡성을 추가하는 여러 기능 값이 포함되지만, 원칙은 동일합니다.

이 예제에서는 앞에서 설명한 아이스크림 판매 시나리오를 살펴보겠습니다. 이 기능의 경우 온도(값이 지정된 날짜의 최대 온도라고 가정)를 고려하고 예측하도록 모델을 학습시키려는 레이블은 그날 판매된 아이스크림의 수입니다. 일일 기온(x) 및 아이스크림 판매(y)에 대한 기록을 포함하는 몇 가지 과거 데이터부터 시작하겠습니다.

| 온도(x) | 아이스크림 매출(y)  |
|-------|--------------|
| 51    | 1            |
| 52    | 0            |
| 67    | 14           |
| 65    | 14           |
| 70    | 23           |
| 69    | 20           |
| 72    | 23           |
| 75    | 26           |
| 73    | 22           |
| 81    | 30           |
| 78    | 26           |
| 83    | 36           |


#### 회귀 모델 학습

먼저 데이터를 분할하고 하위 집합을 사용하여 모델을 학습시킵니다. 학습 데이터 세트는 다음과 같습니다.

| 온도(x) | 아이스크림 매출(y)  |
|-------|--------------|
| 51    | 1            |
| 65    | 14           |
| 69    | 20           |
| 72    | 23           |
| 75    | 26           |
| 81    | 30           |

이러한 x 및 y 값이 서로 어떻게 관련될 수 있는지에 대한 통찰력을 얻으려면 다음과 같이 두 축을 따라 좌표로 그릴 수 있습니다.

![](../img/scatter-plot.png)

이제 학습 데이터에 알고리즘을 적용하고 x에 연산을 적용하여 y를 계산하는 함수에 맞출 준비가 되었습니다. 이러한 알고리즘 중 하나는 선형 회귀로써, 다음과 같이 선과 표시된 점 사이의 평균 거리를 최소화하면서 x와 y 값의 교차점을 통해 직선을 생성하는 함수를 도출하여 작동합니다.

![](../img/regression-line.png)

선은 선의 기울기가 주어진 x 값에 대해 y 값을 계산하는 방법을 설명하는 함수의 시각적 표현입니다. 선은 50에서 x축을 인터셉트하므로 x가 50이면 y는 0입니다. 플롯의 축 마커에서 볼 수 있듯이 x축을 따라 5가 증가할 때마다 y축이 위로 5씩 증가하도록 선이 기울어집니다. 따라서 x가 55일 때 y는 5입니다. x가 60이면 y는 10입니다. 주어진 x 값에 대해 y 값을 계산하기 위해 함수는 단순히 50을 뺍니다. 즉, 함수는 다음과 같이 표현할 수 있습니다.

$f(x) = x-50$

이 함수를 사용하여 지정된 온도로 하루에 판매되는 아이스크림의 수를 예측할 수 있습니다. 예를 들어 일기 예보에서 내일은 화씨 77도(섭씨 25도)가 될 것이라고 가정해 보겠습니다. 모델을 적용하여 77-50을 계산하고 내일 27개의 아이스크림을 판매할 것이라고 예측할 수 있습니다.

하지만 모델이 얼마나 정확한가요?

#### 회귀 모델 평가

모델의 유효성을 검사하고 모델이 얼마나 잘 예측하는지 평가하기 위해 레이블(y) 값을 알고 있는 일부 데이터를 보류했습니다. 보류한 데이터는 다음과 같습니다.

| 온도(x) | 아이스크림 매출(y)  |
|-------|--------------|
| 52    | 0            |
| 67    | 14           |
| 70    | 23           |
| 73    | 22           |
| 78    | 26           |
| 83    | 36           |

모델을 사용하여 기능(x) 값을 기반으로 이 데이터 세트의 각 관측치에 대한 레이블을 예측할 수 있습니다. 그런 다음 예측된 레이블(ŷ)을 알려진 실제 레이블 값(y)과 비교합니다.

함수 f(x) = x-50을 캡슐화하는 앞에서 학습한 모델을 사용하면 다음과 같은 예측을 얻을 수 있습니다.

| 온도(x) | 실제 매출(y) | 예상 매출(ŷ)  |
|-------|----------|-----------|
| 52    | 0        | 2         |
| 67    | 14       | 17        |
| 70    | 23       | 20        |
| 73    | 22       | 23        |
| 78    | 26       | 28        |
| 83    | 36       | 33        |

다음과 같이 기능 값에 대해 예측된 레이블과 실제 레이블을 모두 그릴 수 있습니다.

![](../img/regression-variance.png)

예측된 레이블은 모델에 의해 계산되므로 함수 줄에 있지만 함수에서 계산한 ŷ 값과 유효성 검사 데이터 세트의 실제 y 값 사이에는 약간의 차이가 있습니다. 이는 플롯에서 ŷ와 y 값 사이의 선으로 표시되며, 이는 예측이 실제 값에서 얼마나 멀리 떨어져 있는지를 보여줍니다.

#### 회귀 평가 메트릭

예측 값과 실제 값의 차이점에 따라 회귀 모델을 평가하는 데 사용되는 몇 가지 일반적인 메트릭을 계산할 수 있습니다.

##### MAE(평균 절대 오차)

이 예제의 차이는 각 예측에서 잘못된 아이스크림 수를 나타냅니다. 예측이 실제 값보다 높거나낮았는지 여부는 중요하지 않습니다(예: -3과 +3은 모두 분산이 3임을 나타냄). 이 메트릭은 각 예측에 대한 절대 오차라고 하며 전체 유효성 검사 집합에 대해 평균 절대 오차(MAE)로 요약할 수 있습니다.

아이스크림 예에서 절대 오차(2, 3, 3, 1, 2, 3)의 평균은 2.33입니다.

##### MSE(평균 제곱 오차)

평균 절대 오차 메트릭은 예측 레이블과 실제 레이블 간의 모든 불일치를 동일하게 고려합니다. 그러나 더 적지만 더 큰 오류를 만드는 모델보다 소량으로 일관되게 잘못된 오류를 만드는 모델을 갖는 것이 더 바람직할 수 있습니다. 개별 오차를 제곱하고 제곱 값의 평균을 계산하여 더 큰 오차를 "증폭"하는 메트릭을 생성하는 한 가지 방법입니다. 이 메트릭을 평균 제곱 오차(MSE)라고 합니다.

아이스크림 예에서 제곱 절대값(4, 9, 9, 1, 4, 9)의 평균은 6입니다.

##### RMSE(제곱 평균 오차)

평균 제곱 오차는 오차의 크기를 고려하는 데 도움이 되지만, 오차 값을 제곱하기 때문에 결과 지표는 더 이상 레이블로 측정된 수량을 나타내지 않습니다. 즉, 모델의 MSE는 6이라고 말할 수 있지만, 이는 잘못 예측된 아이스크림 수 측면에서 정확도를 측정하지는 않습니다. 6은 유효성 검사 예측의 오류 수준을 나타내는 숫자 점수일 뿐입니다.

아이스크림 수로 오차를 측정하려면 MSE의 제곱근을 계산해야 합니다. 이는 당연히 제곱 평균 오차라는 메트릭을 생성합니다. 이 경우 √6은 2.45(아이스크림)입니다.

##### 결정 계수($R^2$)

지금까지의 모든 메트릭은 모델을 평가하기 위해 예측 값과 실제 값 간의 불일치를 비교합니다. 그러나 실제로는 모델이 고려한 아이스크림의 일일 판매에서 자연적인 무작위 차이가 있습니다. 선형 회귀 모델에서 학습 알고리즘은 함수와 알려진 레이블 값 간의 평균 차이를 최소화하는 직선에 적합합니다. 결정 계수(보다 일반적으로 R2 또는 R-제곱이라고 함)는 검증 데이터의 일부 비정상적인 측면(예: 지역 축제로 인해 아이스크림 판매량이 매우 특이한 날)과 달리 모델로 설명할 수 있는 검증 결과의 분산 비율을 측정하는 메트릭입니다.

R2에 대한 계산은 이전 메트릭보다 더 복잡합니다. 예측 레이블과 실제 레이블 간의 제곱 차이의 합계를 실제 레이블 값과 실제 레이블 값의 평균 간의 제곱 차이의 합계와 비교합니다.

R2 = 1- ∑(y-ŷ)2 ÷ ∑(y-ȳ)2

복잡해 보이는 경우 너무 걱정하지 마세요. 대부분의 기계 학습 도구는 메트릭을 계산할 수 있습니다. 중요한 점은 결과가 모델에서 설명하는 분산의 비율을 설명하는 0에서 1 사이의 값이라는 것입니다. 간단히 말하면 이 값이 1에 가까울수록 모델이 유효성 검사 데이터에 더 적합합니다. 아이스크림 회귀 모델의 경우, 검증 데이터로부터 계산된 R2는 0.95입니다.

### 반복 학습

위에서 설명한 메트릭은 일반적으로 회귀 모델을 평가하는 데 사용됩니다. 대부분의 실제 시나리오에서 데이터 과학자는 반복 프로세스를 사용하여 다양한 모델을 반복적으로 학습하고 평가합니다.

 - 기능 선택 및 준비(모델에 포함할 기능 선택 및 더 나은 적합성을 보장하기 위해 적용된 계산).
 - 알고리즘 선택(이전 예제에서는 선형 회귀를 살펴보았지만 다른 많은 회귀 알고리즘이 있음)
 - 알고리즘 매개 변수(알고리즘 동작을 제어하기 위한 숫자 설정, 더 정확하게는 x 및 y 매개 변수와 구별하기 위해 하이퍼 매개 변수라고 함)

여러 차례 반복한 후 특정 시나리오에 허용되는 최상의 평가 메트릭을 생성하는 모델이 선택됩니다.

---
## 이진 분류

회귀와 같은 분류는 감독 기계 학습 기술입니다. 따라서 모델을 학습, 검증 및 평가하는 동일한 반복 프로세스를 따릅니다. 회귀 모델과 같은 숫자 값을 계산하는 대신 분류 모델을 학습하는 데 사용되는 알고리즘은 클래스 할당에 대한 확률 값을 계산하고 모델 성능을 평가하는 데 사용되는 평가 메트릭은 예측된 클래스를 실제 클래스와 비교합니다.

이진 분류 알고리즘은 단일 클래스에 대해 가능한 두 레이블 중 하나를 예측하는 모델을 학습하는 데 사용됩니다. 본질적으로 true 또는 false를 예측합니다. 대부분의 실제 시나리오에서 모델을 학습시키고 검증하는 데 사용되는 데이터 관측값은 여러 기능(x) 값과 1 또는 0인 y 값으로 구성됩니다.

### 예제 - 이진 분류

이진 분류의 작동 방식을 이해하기 위해 단일 기능(x)을 사용하여 레이블 y가 1인지 0인지 예측하는 간단한 예제를 살펴보겠습니다. 이 예에서는 환자의 혈당 수준을 사용하여 환자에게 당뇨병이 있는지 여부를 예측합니다. 모델을 학습시킬 데이터는 다음과 같습니다.

| 혈당(x) | 당뇨병 환자? (y)  |
|-------|--------------|
| 67    | 0            |
| 103   | 1            |
| 114   | 1            |
| 72    | 0            |
| 116   | 1            |
| 65    | 0            |

#### 이진 분류 모델 학습

모델을 학습시키기 위해 알고리즘을 사용하여 클래스 레이블이 true일 확률(즉, 환자에게 당뇨병이 있음)을 계산하는 함수에 학습 데이터를 맞춥니다. 확률은 0.0에서 1.0 사이의 값으로 측정되므로 가능한 모든 클래스에 대한 총 확률은 1.0입니다. 예를 들어, 환자가 당뇨병에 걸릴 확률이 0.7이면 환자가 당뇨병이 아닐 확률은 0.3입니다.

로지스틱 회귀와 같이 이진 분류에 사용할 수 있는 많은 알고리즘이 있으며, 이는 다음과 같이 0.0에서 1.0 사이의 값을 가진 시그모이드(S자형) 함수를 파생합니다.

![](../img/sigmoid-plot.png)

참고
```
이름에도 불구하고 기계 학습에서 로지스틱 회귀는 회귀가 아닌 분류에 사용됩니다. 중요한 점은 생성하는 함수의 로지스틱 특성으로, 하한값과 상한값(이진 분류에 사용되는 경우 0.0과 1.0) 사이의 S자형 곡선을 설명합니다.
```

알고리즘에 의해 생성된 함수는 x의 주어진 값에 대해 y가 true(y =1)일 확률을 설명합니다. 수학적으로 다음과 같이 함수를 표현할 수 있습니다.

$f(x) = P(y=1 | x)$

학습 데이터의 6개 관측값 중 3개에 대해 y가 확실히 true라는 것을 알고 있으므로 y = 1인 관측값에 대한 확률은 1.0이고 나머지 3개에 대해 y가 확실히 false라는 것을 알고 있으므로 y = 1일 확률은 0.0입니다. S자형 곡선은 확률 분포를 설명하므로 선에 x 값을 플로팅하면 y가 1일 해당 확률을 식별할 수 있습니다.

다이어그램에는 이 함수를 기반으로 하는 모델이 true(1) 또는 false(0)을 예측하는 임계값을 나타내는 수평선도 포함되어 있습니다. 임계값은 y(P(y) = 0.5)의 중간 지점에 있습니다. 이 지점 이상의 값에 대해 모델은 true(1)를 예측합니다. 이 지점 아래의 값에 대해서는 false(0)를 예측합니다. 예를 들어, 혈당 수준이 90인 환자의 경우 이 함수는 확률 값이 0.9가 될 수 있습니다. 0.9가 임계값 0.5보다 높으므로 모델은 true(1)을 예측합니다. 즉, 환자에게 당뇨병이 있을 것으로 예측됩니다.

#### 이진 분류 모델 평가

회귀와 마찬가지로 이진 분류 모델을 학습할 때 학습된 모델의 유효성을 검사할 데이터의 임의 하위 집합을 보류합니다. 당뇨병 분류자의 유효성을 검사하기 위해 다음 데이터를 보류한 것으로 가정해 보겠습니다.

| 혈당(x) | 당뇨병 환자? (y)  |
|-------|--------------|
| 66    | 0            |
| 107   | 1            |
| 112   | 1            |
| 71    | 0            |
| 87    | 1            |
| 89    | 1            |

이전에 도출한 로지스틱 함수를 x 값에 적용하면 다음과 같은 플롯이 생성됩니다.

![](../img/classification-predictions.png)

함수에 의해 계산된 확률이 임계값 이상인지 또는 그 미만인지에 따라 모델은 각 관찰에 대해 1 또는 0의 예측 레이블을 생성합니다. 그런 다음 다음과 같이 예측된 클래스 레이블(ŷ)을 실제 클래스 레이블(y)과 비교할 수 있습니다.

| 혈당(x) | 실제 당뇨병 진단(y) | 예측된 당뇨병 진단(ŷ)  |
|-------|--------------|----------------|
| 66    | 0            | 0              |
| 107   | 1            | 1              |
| 112   | 1            | 1              |
| 71    | 0            | 0              |
| 87    | 1            | 0              |
| 89    | 1            | 1              |

#### 이진 분류 평가 메트릭

이진 분류 모델에 대한 평가 메트릭을 계산하는 첫 번째 단계는 일반적으로 가능한 각 클래스 레이블에 대한 정확하고 잘못된 예측 수의 행렬을 만드는 것입니다.

![](../img/binary-confusion-matrix.png)

이 시각화를 혼동 행렬이라고 하며, 다음과 같은 경우 예측 합계를 표시합니다.

 - ŷ=0 및 y=0: 진음성(TN)
 - ŷ=1 및 y=0: 가양성(FP)
 - ŷ=0 및 y=1: 가음성(FN)
 - ŷ=1 및 y=1: 진양성(TP)

혼동 행렬의 배열은 올바른(true) 예측이 왼쪽 위에서 오른쪽 아래까지 대각선으로 표시되도록 되어 있습니다. 종종 색 강도는 각 셀의 예측 수를 나타내는 데 사용되므로 잘 예측하는 모델을 한눈에 살펴보면 깊이 음영된 대각선 추세가 표시됩니다.

##### 정확도

혼동 행렬에서 계산할 수 있는 가장 간단한 메트릭은 정확도, 즉 모델이 옳은 예측의 비율입니다. 정확도는 다음과 같이 계산됩니다.

(TN+TP) ÷ (TN+FN+FP+TP)

당뇨병 예제의 경우 계산은 다음과 같습니다.

(2+3) ÷ (2+1+0+3)

= 5 ÷ 6

= 0.83

따라서 유효성 검사 데이터의 경우 당뇨병 분류 모델은 83%의 시간 동안 올바른 예측을 생성했습니다.

정확도는 처음에는 모델을 평가하는 데 좋은 메트릭처럼 보일 수 있지만, 이를 고려합니다. 인구의 11%가 당뇨병을 앓고 있다고 가정해 보겠습니다. 항상 0을 예측하는 모델을 만들 수 있으며, 환자의 특징을 평가하여 환자를 구별하려는 실제 시도가 없더라도 89%의 정확도를 달성할 수 있습니다. 우리에게 정말로 필요한 것은 모델이 양성 사례에 대해 1을 예측하고 음성 사례에 대해 0을 예측하는 방법에 대한 더 깊은 이해입니다.

##### 재현율

재현율은 모델이 올바르게 식별한 양성 사례의 비율을 측정하는 메트릭입니다. 즉, 당뇨병을 앓고 있는 환자의 수와 비교했을 때, 모델은 몇 명이나 당뇨병을 앓고 있을 것으로 예측했는가?

재현율 수식은 다음과 같습니다.

TP ÷ (TP+FN)

당뇨병 예제의 경우:

3 ÷ (3+1)

= 3 ÷ 4

= 0.75

그래서 우리의 모형은 당뇨병이 있는 환자의 75%를 당뇨병이 있는 것으로 정확하게 확인했습니다.

##### 정밀도

정밀도는 재현율과 유사한 메트릭이지만 실제 레이블이 실제로 양성인 예측된 양성 사례의 비율을 측정합니다. 즉, 모델에 의해 당뇨병이 발생할 것으로 예측된 환자 중 실제로 당뇨병을 앓고 있는 환자의 비율은 몇 퍼센트인가?

전체 자릿수에 대한 수식은 다음과 같습니다.

TP ÷ (TP+FP)

당뇨병 예제의 경우:

3 ÷ (3+0)

= 3 ÷ 3

= 1.0

그래서 우리의 모형에 의해 당뇨병으로 예측된 환자의 100%는 실제로 당뇨병이 있습니다.

##### F1 점수

F1 점수는 재현율과 정밀도를 결합한 전체 메트릭입니다. F1 점수에 대한 수식은 다음과 같습니다.

(2 x 정밀도 x 재현율) / (정밀도 + 재현율)

당뇨병 예제의 경우:

(2 x 1.0 x 0.75) ÷ (1.0 + 0.75)

= 1.5 ÷ 1.75

= 0.86

##### 곡선 아래 면적(AUC)

재현율의 또 다른 이름은 TPR(진양성 비율)이며 FP÷(FP+TN)로 계산되는 FPR(가양성 비율)이라는 동등한 메트릭이 있습니다. 임계값 0.5를 사용할 때 모델의 TPR이 0.75라는 것을 이미 알고 있으며 FPR 공식을 사용하여 0÷2 = 0 값을 계산할 수 있습니다.

물론 모델이 true(1)를 예측하는 임계값을 변경하면 긍정 및 부정 예측의 수에 영향을 미칩니다. 따라서 TPR 및 FPR 메트릭을 변경합니다. 이러한 메트릭은 0.0에서 1.0 사이의 가능한 모든 임계값에 대해 TPR과 FPR을 비교하는 ROC(수신 연산자 특성) 곡선을 그려 모델을 평가하는 데 자주 사용됩니다.

![](../img/roc-chart.png)

완벽한 모델을 위한 ROC 곡선은 왼쪽의 TPR 축을 똑바로 위로 이동한 다음 위쪽의 FPR 축을 가로질러 이동합니다. 곡선의 플롯 영역은 1x1을 측정하므로 이 완벽한 곡선 아래의 영역은 1.0이 됩니다(모델이 항상 100% 정확하다는 의미). 반면 왼쪽 아래에서 오른쪽 위까지의 대각선은 이진 레이블을 임의로 추측하여 달성되는 결과를 나타냅니다. 0.5의 곡선 아래 영역을 생성합니다. 즉, 두 개의 가능한 클래스 레이블을 고려할 때 50%의 확률로 정확하게 추측할 것으로 합리적으로 기대할 수 있습니다.

당뇨병 모델의 경우 위의 곡선이 생성되고 AUC(Area Under the Curve) 메트릭은 0.875입니다. AUC가 0.5보다 높기 때문에, 우리는 모델이 무작위로 추측하는 것보다 환자가 당뇨병이 있는지 여부를 예측하는 데 더 나은 성능을 발휘하는 것으로 결론을 내릴 수 있습니다.

---
## 다중 클래스 분류

다중클래스 분류는 관찰이 여러 가능한 클래스 중 어느 클래스에 속하는지 예측하는 데 사용됩니다. 감독형 기계 학습 기술로서 학습된 모델을 검증하기 위해 학습 데이터의 하위 집합을 보류하는 회귀 및 이진 분류와 동일한 반복 학습, 검증 및 평가 프로세스를 따릅니다.

### 예제 - 다중 클래스 분류

다중 클래스 분류 알고리즘은 다중 클래스 레이블에 대한 확률 값을 계산하는 데 사용되며, 이를 통해 모델은 주어진 관찰에 대해 가장 가능성이 높은 클래스를 예측할 수 있습니다.

각 펭귄의 지느러미 길이(x)가 기록되는 펭귄 관찰 사례를 살펴보겠습니다. 각 관측값에 대해 데이터에는 다음과 같이 인코딩된 펭귄 종(y)이 포함됩니다.

 - 0: Adelie
 - 1: Gentoo
 - 2: Chinstrap

참고
```
이 모듈의 이전 예제와 마찬가지로 실제 시나리오에는 여러 기능(x) 값이 포함됩니다. 단일 기능을 사용하여 작업을 간단하게 유지합니다.
```

| 플리퍼 길이(x) | 종(y)  |
|-----------|-------|
| 167       | 0     |
| 172       | 0     |
| 225       | 2     |
| 197       | 1     |
| 189       | 1     |
| 232       | 2     |
| 158       | 0     |

#### 다중 클래스 분류 모델 학습

다중 클래스 분류 모델을 학습하려면 알고리즘을 사용하여 학습 데이터를 가능한 각 클래스의 확률 값을 계산하는 함수에 맞춰야 합니다. 이 작업을 수행하는 데 사용할 수 있는 알고리즘에는 두 가지 종류가 있습니다.

 - OvR(One-vs-Rest) 알고리즘
 - 다항식 알고리즘

##### OvR(One-vs-Rest) 알고리즘

One-vs-Rest 알고리즘은 각 클래스에 대해 이진 분류 함수를 학습하며, 각 클래스는 관찰이 대상 클래스의 예시일 확률을 계산합니다. 각 함수는 관측값이 다른 클래스와 비교하여 특정 클래스일 확률을 계산합니다. 펭귄 종 분류 모델의 경우 알고리즘은 기본적으로 세 가지 이진 분류 함수를 만듭니다.

 - $f0(x) = P(y=0 | x)$
 - $f1(x) = P(y=1 | x)$
 - $f2(x) = P(y=2 | x)$

각 알고리즘은 0.0에서 1.0 사이의 확률 값을 계산하는 시그모이드 함수를 생성합니다. 이러한 종류의 알고리즘을 사용하여 학습된 모델은 가장 높은 확률 출력을 생성하는 함수의 클래스를 예측합니다.

##### 다항식 알고리즘

다른 방법은 다중 값 출력을 반환하는 단일 함수를 만드는 다항 알고리즘을 사용하는 것입니다. 출력은 가능한 모든 클래스에 대한 확률 분포를 포함하는 벡터(값 배열)입니다. 각 클래스에 대한 확률 점수는 총합이 1.0이 됩니다.

$f(x) =[P(y=0|x), P(y=1|x), P(y=2|x)]$

이러한 종류의 함수의 예로는 다음 예제와 같은 출력을 생성할 수 있는 softmax 함수가 있습니다.

[0.2, 0.3, 0.5]

벡터의 요소는 각각 클래스 0, 1, 2에 대한 확률을 나타냅니다. 따라서 이 경우 확률이 가장 높은 클래스는 2입니다.

어떤 유형의 알고리즘이 사용되는지에 관계없이 모델은 결과 함수를 사용하여 주어진 특징 세트(x)에 대해 가장 가능성이 높은 클래스를 결정하고 해당 클래스 레이블(y)을 예측합니다.

#### 다중 클래스 분류 모델 평가

각 개별 클래스에 대한 이진 분류 메트릭을 계산하여 다중 클래스 분류자를 평가할 수 있습니다. 또는 모든 클래스를 고려한 집계 메트릭을 계산할 수 있습니다.

다중 클래스 분류자의 유효성을 검사하고 다음 결과를 얻었다고 가정해 보겠습니다.

| 플리퍼 길이(x) | 실제 종(y) | 예상 종(ŷ)  |
|-----------|---------|----------|
| 165       | 0       | 0        |
| 171       | 0       | 0        |
| 205       | 2       | 1        |
| 195       | 1       | 1        |
| 183       | 1       | 1        |
| 221       | 2       | 2        |
| 214       | 2       | 2        |

다중클래스 분류기의 혼동 행렬은 예측된 클래스 레이블(ŷ)과 실제 클래스 레이블(y)의 각 조합에 대한 예측 수를 표시한다는 점을 제외하면 이진 분류기와 유사합니다.

![](../img/multiclass-confusion-matrix.png)

이 혼동 행렬에서 다음과 같이 각 개별 클래스에 대한 메트릭을 확인할 수 있습니다.

| 클래스 | TP | TN | FP | FN | 정확도  | 재현율  | 정밀도  | F1 점수  |
|-----|----|----|----|----|------|------|------|--------|
| 0   | 2  | 5  | 0  | 0  | 1.0  | 1.0  | 1.0  | 1.0    |
| 1   | 2  | 4  | 1  | 0  | 0.86 | 1.0  | 0.67 | 0.8    |
| 2   | 2  | 4  | 0  | 1  | 0.86 | 0.67 | 1.0  | 0.8    |

전체 정확도, 재현율 및 정밀도 메트릭을 계산하려면 TP, TN, FP 및 FN 메트릭의 합계를 사용합니다.

 - 전체 정확도 = (13+6)÷(13+6+1+1) = 0.90
 - 전체 재현율 = 6÷(6+1) = 0.86
 - 전체 정밀도 = 6÷(6+1) = 0.86

전체 F1 점수는 전체 재현율 및 정밀도 메트릭을 사용하여 계산됩니다.

 - 전체 F1 점수 = (2x0.86x0.86)÷(0.86+0.86) = 0.86

---
## Clustering

클러스터링은 데이터 값의 유사성 또는 기능에 따라 관찰 내용이 클러스터로 그룹화되는 자율형 기계 학습 형태입니다. 이러한 유형의 기계 학습은 이전에 알려진 레이블 값을 사용하여 모델을 학습시키지 않기 때문에 감독되지 않는 학습으로 간주됩니다. 클러스터링 모델에서 레이블은 관련 특징만을 기준으로 관찰이 할당되는 클러스터입니다.

### 예제 - 클러스터링

예를 들어 식물학자가 꽃 샘플을 관찰하고 각 꽃의 꽃잎과 나뭇잎 수를 기록한다고 가정해 봅시다.

![](../img/flowers.png)

데이터 세트에는 알려진 레이블이 없으며 두 가지 기능만 있습니다. 목표는 꽃의 유형(종)을 식별하는 것이 아닙니다; 잎과 꽃잎의 수에 따라 비슷한 꽃을 함께 그룹화하기만 하면 됩니다.

| 잎(x1) | 꽃잎(x2)  |
|-------|---------|
| 0     | 5       |
| 0     | 6       |
| 1     | 3       |
| 1     | 3       |
| 1     | 6       |
| 1     | 8       |
| 2     | 3       |
| 2     | 7       |
| 2     | 8       |


#### 클러스터링 모델 학습

클러스터링에 사용할 수 있는 다양한 알고리즘이 존재합니다. 가장 일반적으로 사용되는 알고리즘 중 하나는 다음과 같은 단계로 구성되는 K-평균 클러스터링입니다.

 1. n-차원 좌표를 정의하기 위해 기능(x) 값이 벡터화됩니다(여기서 n은 특징의 개수입니다). 꽃 예제에서 잎의 수(x1)와 꽃잎 수(x2)라는 두 가지 특징이 있습니다. 따라서 기능 벡터에는 2차원 공간에 개념적으로 데이터 요소를 그리는 데 사용할 수 있는 두 개의 좌표가 있습니다([x1,x2]).
 2. 꽃들을 그룹화하는 데 사용하려는 클러스터 개수를 정하고 이 값을 k라고 부릅니다. 예를 들어 클러스터 3개를 만들려면 k 값에 3을 사용합니다. 그러면 k 지점이 임의 좌표에 그려집니다. 이러한 지점들은 각 클러스터의 중심점이 되므로 중심이라고 부릅니다.
 3. 각 데이터 지점(이 경우에는 꽃)이 가장 가까운 중심에 할당됩니다.
 4. 각 중심은 점수 간의 평균 거리를 기준으로 해당 개체에 할당된 데이터 요소의 가운데로 이동됩니다.
 5. 중심이 옮겨진 후 데이터 요소가 다른 중심에 더 가까이 있게 될 수도 있으므로, 가장 가까운 새 중심을 기반으로 데이터 요소가 클러스터에 재할당됩니다.
 6. 중심 이동 및 클러스터 재할당 단계는 클러스터가 안정되거나 사전에 정해진 최대 반복 횟수에 도달할 때까지 반복됩니다.

다음 애니메이션은 해당 프로세스를 나타냅니다.

![](../img/clustering.gif)

#### 클러스터링 모델 평가

예측된 클러스터 할당을 비교할 수 있는 알려진 레이블이 없으므로 클러스터링 모델의 평가는 결과 클러스터가 서로 얼마나 잘 분리되는지에 따라 이루어집니다.

클러스터 분리를 평가하는 데 사용할 수 있는 메트릭에 다음을 포함하여 여러 가지가 있습니다.

 - 클러스터 중심까지의 평균 거리: 클러스터의 각 지점과 클러스터의 중심이 평균적으로 얼마나 가까운지 나타냅니다.
 - 다른 중심까지의 평균 거리: 클러스터의 각 지점과 다른 모든 클러스터의 중심이 평균적으로 얼마나 가까운지 나타냅니다.
 - 클러스터 중심까지의 최대 거리: 클러스터의 지점과 중심점 사이의 가장 먼 거리입니다.
 - 실루엣: -1에서 1 사이의 값으로, 동일한 클러스터의 점과 서로 다른 클러스터의 점 간의 거리 비율을 요약합니다(1에 가까울수록 클러스터 분리가 잘 되어 있음).

---
## 딥 러닝

‘딥 러닝’은 인간 두뇌가 학습하는 방식을 에뮬레이트하는 고급 형태의 기계 학습입니다. 딥 러닝의 핵심은 여기에 표시된 것처럼 수학적 함수를 사용하여 생물학적 뉴런에서 전기 화학 활동을 시뮬레이션하는 인공 신경망을 만드는 것입니다.

| 생물학적 신경망                                          | 인공 신경망                                                                    |
|---------------------------------------------------|---------------------------------------------------------------------------|
| ![](../img/biological-neural-network.png) | ![](../img/artificial-neural-network.png) |
| 뉴런은 전기 화학 자극에 반응하여 발화합니다. 발화되면 신호가 연결된 뉴런에 전달됩니다. | 각 뉴런은 입력 값(x) 및 가중치(w)에서 작동하는 함수입니다. 함수는 출력을 전달할지 여부를 결정하는 활성화 함수로 래핑됩니다. |

인공 신경망은 여러 층의 뉴런으로 구성되어 있으며, 기본적으로 심층적으로 중첩된 기능을 정의합니다. 이 아키텍처는 이 기술을 딥 러닝이라고 하며 이런 이유로 이 기술을 통해 생성된 모델을 DNN(심층 신경망)이라고도 합니다. 회귀 및 분류를 비롯한 다양한 종류의 기계 학습 문제와 자연어 처리 및 컴퓨터 비전을 위한 보다 전문화된 모델에 심층 신경망을 사용할 수 있습니다.

이 모듈에서 설명하는 다른 기계 학습 기술과 마찬가지로 딥 러닝에는 하나 이상의 기능(x)의 값을 기반으로 레이블(y)을 예측할 수 있는 함수에 학습 데이터를 맞추는 작업이 포함됩니다. 함수(f(x))는 신경망의 각 계층이 x에서 작동하는 함수와 연결된 가중치(w) 값을 캡슐화하는 중첩 함수의 외부 계층입니다. 모델을 학습시키는 데 사용되는 알고리즘에는 계층을 통해 학습 데이터의 기능 값(x)을 반복적으로 공급하여 ŷ에 대한 출력 값을 계산하고, 모델에서 계산된 ŷ 값이 알려진 y 값에서 얼마나 멀리 떨어져 있는지 평가하도록 유효성을 검사합니다(모델의 오류 또는 손실 수준을 정량화함). 그런 다음, 손실을 줄이기 위해 가중치(w)를 수정합니다. 학습된 모델에는 가장 정확한 예측을 생성하는 최종 가중치 값이 포함됩니다.

### 예제 - 분류에 딥 러닝 사용

심층 신경망 모델의 작동 방식을 더 잘 이해하기 위해 신경망이 펭귄 종의 분류 모델을 정의하는 데 사용되는 예제를 살펴보겠습니다.

![](../img/deep-classification.png)

특징 데이터(x)는 펭귄의 일부 측정값으로 구성됩니다. 구체적인 측정값은 다음과 같습니다.

 - 펭귄의 부리 길이
 - 펭귄의 부리 깊이
 - 펭귄의 물갈퀴 길이
 - 펭귄의 무게

이 경우 특성(x)은 네 값의 벡터 또는 수학적으로 $x=[x1,x2,x3,x4]$입니다.

예측하려는 레이블(y)은 펭귄의 종이며, 가능한 종은 다음 세 가지라고 가정해 보겠습니다.

 - Adelie
 - Gentoo
 - Chinstrap

이것은 분류 문제에 대한 예제입니다. 이 예제에서는 해당 관찰이 속할 가능성이 가장 높은 클래스를 기계 학습 모델이 예측해야 합니다. 분류 모델은 각 클래스에 대한 확률로 구성된 레이블을 예측하여 이 작업을 수행합니다. 즉, y는 가능한 클래스마다 하나씩으로 된 세 확률 값의 벡터인 $[P(y=0|x), P(y=1|x), P(y=2|x)]$입니다.

이 네트워크를 사용하여 예측된 펭귄 클래스를 유추하는 프로세스는 다음과 같습니다.

 1. 펭귄 관찰을 위한 특징 벡터는 각 x 값에 대한 뉴런으로 구성된 신경망의 입력 계층에 공급됩니다. 이 예제에서는 다음 x 벡터가 입력으로 사용됩니다. [37.3, 16.8, 19.2, 30.0]
 2. 뉴런의 첫 번째 계층에 대한 함수는 각각 x 값과 w 가중치를 결합하여 가중치 합계를 계산하고 다음 계층에 전달할 임계값을 충족하는지 여부를 결정하는 활성화 함수에 전달합니다.
 3. 레이어의 각 뉴런은 다음 계층의 모든 뉴런에 연결되므로(완전히 연결된 네트워크라고도 하는 아키텍처) 각 레이어의 결과가 출력 계층에 도달할 때까지 네트워크를 통해 전달됩니다.
 4. 출력 계층은 값의 벡터를 생성합니다. 이 경우 softmax 또는 유사한 함수를 사용하여 펭귄의 세 가지 가능한 클래스에 대한 확률 분포를 계산합니다. 이 예제에서 출력 벡터는 [0.2, 0.7, 0.1]입니다.
 5. 벡터의 요소는 클래스 0, 1, 2의 확률을 나타냅니다. 두 번째 값이 가장 높으므로 모델은 펭귄의 종을 1(젠투)이라고 예측합니다.

#### 신경망은 어떻게 학습하나요?

신경망의 가중치는 레이블에 대해 예측된 값을 계산하는 방법의 중심입니다. 학습 프로세스 중에 모델은 가장 정확한 예측을 생성하는 가중치를 학습합니다. 이 학습이 어떻게 진행되는지 이해하기 위해 학습 프로세스를 좀 더 자세히 살펴보겠습니다.

![](../img/neural-network-training.png)

 1. 학습 및 유효성 검사 데이터 세트가 정의되고 학습 기능이 입력 계층에 공급됩니다.
 2. 네트워크의 각 계층에 있는 뉴런은 가중치(처음에 무작위로 할당됨)를 적용하고 네트워크를 통해 데이터를 공급합니다.
 3. 출력 계층은 ŷ에 대한 계산 값을 포함하는 벡터를 생성합니다. 예를 들어 펭귄 클래스 예측의 출력은 [0.3. 0.1. 0.6]입니다.
 4. 손실 함수는 예측된 ŷ 값을 알려진 y 값과 비교하고 차이(손실이라고 함)를 집계하는 데 사용됩니다. 예를 들어 이전 단계에서 출력을 반환한 사례에 대해 알려진 클래스가 친스트랩인 경우 y 값은 [0.0, 0.0, 1.0]이어야 합니다. 이 벡터와 ŷ 벡터 간의 절대적인 차이점은 [0.3, 0.1, 0.4]입니다. 실제로 손실 함수는 여러 사례에 대한 집계 분산을 계산하고 단일 손실 값으로 합산합니다.
 5. 전체 네트워크는 기본적으로 하나의 큰 중첩 함수이므로 최적화 함수는 차등 계산기를 사용하여 손실에 대한 네트워크의 각 가중치의 영향을 평가하고 전체 손실의 양을 줄이기 위해 조정(위쪽 또는 아래로)할 수 있는 방법을 결정할 수 있습니다. 특정 최적화 기술은 다를 수 있지만 일반적으로 손실을 최소화하기 위해 각 가중치가 증가하거나 감소되는 경사 하강 방식을 포함합니다.
 6. 가중치 변경 내용은 네트워크의 계층으로 역전파되어 이전에 사용된 값을 대체합니다.
 7. 이 프로세스는 손실이 최소화되고 모델이 허용 가능한 정확하게 예측될 때까지 여러 반복(epoch라고 함)을 통해 반복됩니다.

참고
```
네트워크를 통해 한 번에 하나씩 전달되는 학습 데이터의 각 사례를 쉽게 생각할 수 있지만 실제로 데이터는 행렬로 일괄 처리되고 선형 대수 계산을 사용하여 처리됩니다. 이러한 이유로 신경망 학습은 벡터 및 행렬 조작에 최적화된 GPU(그래픽 처리 장치)가 있는 컴퓨터에서 가장 잘 수행됩니다.
```

---
## Azure Machine Learning

Microsoft Azure Machine Learning은 기계 학습 모델을 학습, 배포 및 관리하기 위한 클라우드 서비스입니다. 데이터 과학자, 소프트웨어 엔지니어, devops 전문가 및 기타 사용자가 다음을 포함한 기계 학습 프로젝트의 종단 간 수명 주기를 관리하는 데 사용하도록 설계되었습니다.

 - 데이터를 탐색하고 모델링을 위해 준비합니다.
 - 기계 학습 모델을 학습 및 평가합니다.
 - 학습된 모델 등록 및 관리
 - 애플리케이션 및 서비스에서 사용할 학습된 모델을 배포합니다.
 - 책임 있는 AI 원칙 및 사례를 검토하고 적용합니다.

### Azure Machine Learning의 특징 및 기능

Azure Machine Learning은 기계 학습 워크로드를 지원하기 위해 다음과 같은 기능과 특징을 제공합니다.

 - 모델 학습 및 평가를 위한 데이터 세트의 중앙 집중식 스토리지 및 관리.
 - 모델 학습과 같은 기계 학습 작업을 실행할 수 있는 주문형 컴퓨팅 리소스.
 - AutoML(자동화된 Machine Learning)을 사용하면 다양한 알고리즘과 매개 변수를 사용하여 여러 학습 작업을 쉽게 실행하여 데이터에 가장 적합한 모델을 찾을 수 있습니다.
 - 모델 학습 또는 추론과 같은 프로세스에 대해 오케스트레이션된 파이프라인을 정의하는 시각적 도구입니다.
 - MLflow와 같은 일반적인 기계 학습 프레임워크와 통합하면 모델 학습, 평가 및 배포를 대규모로 쉽게 관리할 수 있습니다.
 - 모델 설명 가능성, 공정성 평가 등을 포함하여 책임 있는 AI에 대한 메트릭을 시각화하고 평가하기 위한 기본 제공 지원.

### Azure Machine Learning 리소스 프로비전

Azure Machine Learning에 필요한 기본 리소스는 Azure 구독에서 프로비전할 수 있는 Azure Machine Learning 작업 영역입니다. 스토리지 계정, 컨테이너 레지스트리, 가상 머신 등을 비롯한 기타 지원 리소스는 필요에 따라 자동으로 만들어집니다.

Azure Machine Learning 작업 영역을 만들려면 다음과 같이 Azure Portal을 사용할 수 있습니다.

![](../img/azure-portal.png)

### Azure Machine Learning Studio

Azure Machine Learning 작업 영역을 프로비전한 후 Azure Machine Learning 스튜디오에서 사용할 수 있습니다. 기계 학습 리소스 및 작업을 관리하기 위한 브라우저 기반 포털입니다.

Azure Machine Learning 스튜디오에서는 무엇보다도 다음을 수행할 수 있습니다.

 - 데이터 가져오기 및 내보내기
 - 컴퓨팅 리소스를 만들고 사용합니다.
 - Notebook에서 코드를 실행합니다.
 - 시각적 도구를 사용하여 작업 및 파이프라인을 만듭니다.
 - 자동화된 Machine Learning을 사용하여 모델을 학습하세요.
 - 평가 메트릭, 책임 있는 AI 정보 및 학습 매개 변수를 포함하여 학습된 모델의 세부 정보를 봅니다.
 - 요청 및 일괄 처리 추론을 위해 학습된 모델을 배포합니다.
 - 종합적인 모델 카탈로그에서 모델을 가져오고 관리합니다.

![](../img/azure-ml-studio.png)

스크린샷은 학습된 다중 클래스 분류 모델에 대한 평가 메트릭을 볼 수 있는 Azure Machine Learning Studio의 학습된 모델에 대한 메트릭 페이지를 보여줍니다.

---
## 연습 - Azure Machine Learning에서 자동화된 Machine Learning 살펴보기

[다음 페이지](https://learn.microsoft.com/ko-kr/training/modules/fundamentals-machine-learning/10-exercise-auto-ml)에서 진행합니다.

이 연습에서는 [Azure Machine Learning 스튜디오](https://ml.azure.com/)의 자동화된 ML 기능을 살펴보고 이를 사용하여 기계 학습 모델을 학습하고 평가합니다.

참고
```
아직 없는 경우 처음 30일 동안 무료 크레딧을 포함하는 [Azure 구독에 등록](https://azure.microsoft.com/free)할 수 있습니다.
```

연습을 시작하고 지침을 따릅니다.

**TODO**
 1. 실습 사이트 번역, 정리
 2. 실습 스크린샷

---
## 요약

기계 학습은 인공 지능이 구축되는 기반입니다. 이 모듈에서는 기계 학습의 기반이 되는 몇 가지 핵심 원칙 및 개념과 학습 및 평가할 수 있는 다양한 종류의 모델에 대해 알아보았습니다.

이 모듈은 또한 엔드투엔드 기계 학습 작업을 위한 클라우드 플랫폼인 Azure Machine Learning을 소개하고 Azure Machine Learning에서 자동화된 기계 학습을 직접 사용할 수 있는 기회를 제공했습니다.

팁

Azure Machine Learning 및 해당 기능에 대한 자세한 내용은 [Azure Machine Learning](https://azure.microsoft.com/products/machine-learning/) 페이지를 참조하세요.


---
## 출처
[Microsoft learn 기계 학습의 기본 사항](https://learn.microsoft.com/ko-kr/training/modules/fundamentals-machine-learning/)